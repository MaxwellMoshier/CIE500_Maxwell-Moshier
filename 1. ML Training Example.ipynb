{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Basic Neural Network with PyTorch â€” Iris Dataset\n",
        "\n",
        "1. Load and inspect data  \n",
        "2. Train / validation / test split  \n",
        "3. Data preprocessing (scaling)  \n",
        "4. Build a basic neural network (MLP)  \n",
        "5. Training loop  \n",
        "6. Testing and evaluation  \n",
        "\n",
        "The Iris dataset is fully numeric and clean, so preprocessing focuses on **scaling and splitting**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "# sklearn\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load and Inspect the Iris Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              " 0                5.1               3.5                1.4               0.2   \n",
              " 1                4.9               3.0                1.4               0.2   \n",
              " 2                4.7               3.2                1.3               0.2   \n",
              " 3                4.6               3.1                1.5               0.2   \n",
              " 4                5.0               3.6                1.4               0.2   \n",
              " \n",
              "    label  \n",
              " 0      0  \n",
              " 1      0  \n",
              " 2      0  \n",
              " 3      0  \n",
              " 4      0  ,\n",
              " label\n",
              " 0    50\n",
              " 1    50\n",
              " 2    50\n",
              " Name: count, dtype: int64)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "feature_names = iris.feature_names\n",
        "target_names = iris.target_names\n",
        "\n",
        "df = pd.DataFrame(X, columns=feature_names)\n",
        "df[\"label\"] = y\n",
        "\n",
        "df.head(), df[\"label\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Train / Validation / Test Split\n",
        "\n",
        "We split first to avoid data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 105\n",
            "Val size:   22\n",
            "Test size:  23\n"
          ]
        }
      ],
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.50, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Val size:  \", len(X_val))\n",
        "print(\"Test size: \", len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Data Preprocessing: Feature Scaling\n",
        "\n",
        "Neural networks are sensitive to feature scales.\n",
        "We **fit the scaler on training data only**, then apply it to validation and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 2.38327876e-15, -1.12145742e-15, -1.37456184e-16, -6.97854473e-17]),\n",
              " array([1., 1., 1., 1.]))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled   = scaler.transform(X_val)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled.mean(axis=0), X_train_scaled.std(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Convert to PyTorch Tensors and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([[-0.0854, -0.7807,  0.1775, -0.2658],\n",
              "         [ 0.4968,  0.5379,  1.2476,  1.6726],\n",
              "         [-0.9005,  0.9775, -1.3431, -1.2996],\n",
              "         [-0.7840,  2.2961, -1.2868, -1.4289],\n",
              "         [-0.9005,  0.7577, -1.2868, -1.2996],\n",
              "         [ 1.0790,  0.3181,  1.1913,  1.4141],\n",
              "         [-0.6676,  1.4170, -1.2868, -1.2996],\n",
              "         [-0.2018, -1.0005, -0.1604, -0.2658],\n",
              "         [ 1.5448,  0.3181,  1.2476,  0.7680],\n",
              "         [-0.3183, -0.5609,  0.6281,  1.0264],\n",
              "         [-0.2018, -0.1214,  0.2339, -0.0074],\n",
              "         [-1.1333, -0.1214, -1.3431, -1.2996],\n",
              "         [ 2.3598,  1.6368,  1.4729,  1.0264],\n",
              "         [ 0.9626, -0.1214,  0.7971,  1.4141],\n",
              "         [-0.5511,  1.8565, -1.1742, -1.0412],\n",
              "         [-1.0169,  0.7577, -1.2305, -1.0412]]),\n",
              " tensor([1, 2, 0, 0, 0, 2, 0, 1, 2, 2, 1, 0, 2, 2, 0, 0])]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "X_val_t   = torch.tensor(X_val_scaled,   dtype=torch.float32)\n",
        "X_test_t  = torch.tensor(X_test_scaled,  dtype=torch.float32)\n",
        "\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "y_val_t   = torch.tensor(y_val,   dtype=torch.long)\n",
        "y_test_t  = torch.tensor(y_test,  dtype=torch.long)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t),\n",
        "                          batch_size=16, shuffle=True)\n",
        "val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t),\n",
        "                          batch_size=32, shuffle=False)\n",
        "test_loader  = DataLoader(TensorDataset(X_test_t, y_test_t),\n",
        "                          batch_size=32, shuffle=False)\n",
        "\n",
        "next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Define a Basic Neural Network (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (net): Sequential(\n",
              "    (0): Linear(in_features=4, out_features=32, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=32, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = MLP(input_dim=4, hidden_dim=32, num_classes=3)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Training Loop (with Validation Accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 001 | Loss: 0.8642 | Val Acc: 0.818\n",
            "Epoch 020 | Loss: 0.0338 | Val Acc: 0.909\n",
            "Epoch 040 | Loss: 0.0072 | Val Acc: 0.909\n",
            "Epoch 060 | Loss: 0.0017 | Val Acc: 0.909\n",
            "Epoch 080 | Loss: 0.0010 | Val Acc: 0.909\n",
            "Epoch 100 | Loss: 0.0007 | Val Acc: 0.909\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate_accuracy(loader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += (pred == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "    return correct / total\n",
        "\n",
        "def train_one_epoch(loader):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "n_epochs = 100\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    loss = train_one_epoch(train_loader)\n",
        "    val_acc = evaluate_accuracy(val_loader)\n",
        "    if epoch % 20 == 0 or epoch == 1:\n",
        "        print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val Acc: {val_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Final Test Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9565217391304348\n",
            "Classification report:               precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00         7\n",
            "  versicolor       0.89      1.00      0.94         8\n",
            "   virginica       1.00      0.88      0.93         8\n",
            "\n",
            "    accuracy                           0.96        23\n",
            "   macro avg       0.96      0.96      0.96        23\n",
            "weighted avg       0.96      0.96      0.96        23\n",
            "\n",
            "Confusion matrix: [[7 0 0]\n",
            " [0 8 0]\n",
            " [0 1 7]]\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def predict(loader):\n",
        "    model.eval()\n",
        "    y_true, y_pred = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device)\n",
        "        logits = model(xb)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        y_true.append(yb.numpy())\n",
        "        y_pred.append(pred.cpu().numpy())\n",
        "    return np.concatenate(y_true), np.concatenate(y_pred)\n",
        "\n",
        "y_true, y_pred = predict(test_loader)\n",
        "\n",
        "print(\"Test accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"Classification report:\", classification_report(y_true, y_pred, target_names=target_names))\n",
        "print(\"Confusion matrix:\", confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "CIE500",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
